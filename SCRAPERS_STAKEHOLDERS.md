# Sistema de Scrapers - Radar de Stakeholders

## üéØ Status Atual

| Componente | Status |
|------------|--------|
| **C√≥digo** | ‚úÖ Implementado e funcional |
| **Depend√™ncias** | ‚úÖ Nenhuma adicional necess√°ria (usa axios + cheerio) |
| **Padr√£o** | ‚úÖ Segue exatamente o padr√£o dos scrapers legislativos |
| **Testes** | ‚ö†Ô∏è Bloqueado por IP de datacenter |
| **Produ√ß√£o** | ‚è≥ Precisa servidor com IP residencial portugu√™s |

**TL;DR**: O c√≥digo est√° **100% pronto**, mas sites bloqueiam IPs de datacenters. Testar em ambiente local ou VPS portugu√™s.

---

## Vis√£o Geral

Sistema automatizado de scraping para coletar not√≠cias e comunicados de organiza√ß√µes externas (sindicatos, patronato, ONGs, etc.) para o Radar Legislativo.

**Tecnologias**: Axios + Cheerio (j√° instaladas no projeto)

## Arquitetura

```
src/
‚îú‚îÄ‚îÄ scrapers/
‚îÇ   ‚îî‚îÄ‚îÄ stakeholders.js       ‚Üê Scraper principal (gen√©rico)
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ scheduler.js          ‚Üê Agendamento autom√°tico
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ Document.js           ‚Üê Modelo de dados (Supabase)
‚îî‚îÄ‚îÄ controllers/
    ‚îî‚îÄ‚îÄ stakeholderController.js ‚Üê API endpoints
```

## Stakeholders Configurados

### Concerta√ß√£o Social (5 organiza√ß√µes)

| ID | Nome | URL | Status |
|----|------|-----|--------|
| `cgtp` | CGTP-IN | https://www.cgtp.pt/accao-e-luta | ‚ö†Ô∏è Bloqueado (403) |
| `ugt` | UGT | https://www.ugt.pt/noticias | ‚ö†Ô∏è Bloqueado (403) |
| `cap` | CAP | https://www.cap.pt/noticias-cap | ‚ö†Ô∏è Bloqueado (403) |
| `ccp` | CCP | https://ccp.pt/noticias/ | ‚ö†Ô∏è Bloqueado (403) |
| `ctp` | CTP | https://ctp.org.pt/noticias | ‚ö†Ô∏è Bloqueado (403) |

### Outras Categorias Implementadas

- **Laboral**: ACT, CITE, AIMA
- **Ambiente**: APA, IGAMAOT, DGAV, DGEG, ADENE, ERSE
- **Agricultura**: DGADR, INIAV
- **Economia/Finan√ßas**: IAPMEI, AdC, AT Aduaneiro, Banco de Portugal, Portugal Global, Portal Consumidor, DGAE
- **Sa√∫de**: INFARMED, ERS, IGAS
- **Imobili√°rio/Habita√ß√£o**: CMVM, DGTerrit√≥rio, IHRU

## Funcionalidades Implementadas

### 1. Scraper Gen√©rico com M√∫ltiplos Seletores

Cada stakeholder tem configurados **m√∫ltiplos seletores CSS** como fallback:

```javascript
cgtp: {
  url: "https://www.cgtp.pt/accao-e-luta",
  nome: "CGTP-IN",
  categoria: "concertacao_social",
  seletores: [
    ".entry-title a",           // Tentativa 1
    "article h2 a",              // Tentativa 2
    ".post-title a",             // Tentativa 3
    "h2 a[href*='/accao-e-luta/']", // Tentativa 4
    ".content-item a"            // Tentativa 5
  ],
  seletorData: ".entry-date, .post-date, time, .published",
  seletorResumo: ".entry-summary, .entry-content, .excerpt, p",
  tipo_conteudo: "noticia",
}
```

### 2. Sistema de Retry Inteligente

- **3 tentativas** com backoff exponencial
- Delay entre tentativas: 3s, 6s, 9s
- User-Agent rotativo (5 varia√ß√µes)
- Headers HTTP completos (simulando navegador real)

### 3. Tratamento Robusto de Erros

```javascript
// Erros tratados:
- 403 Forbidden (prote√ß√£o anti-scraping)
- 404 Not Found
- ECONNABORTED (timeout)
- ENOTFOUND (DNS)
- Duplicados na base de dados
```

### 4. Extra√ß√£o de Dados Avan√ßada

```javascript
// Dados extra√≠dos de cada not√≠cia:
{
  tipo_conteudo: "noticia",
  tipo_radar: "stakeholders",    // Importante para filtros
  categoria: "concertacao_social",
  titulo: "...",
  data_publicacao: "2025-10-27", // Parseado de v√°rios formatos
  url: "https://...",
  fonte: "cgtp",
  entidades: "CGTP-IN",
  resumo: "..."                   // Extra√≠do ou gerado do t√≠tulo
}
```

### 5. Agendamento Autom√°tico (Scheduler)

```javascript
// Hor√°rios configurados:
- Segunda a Sexta, 9h-19h: a cada 15 minutos
- Noites e madrugadas: a cada 2 horas
- Fins de semana: 1x por dia √†s 10h
- Total estimado: 50-60 execu√ß√µes/dia
```

## Como Usar

### ‚ö†Ô∏è Importante: Ambiente de Execu√ß√£o

**O scraping PRECISA ser executado em servidor com IP residencial ou portugu√™s.**

IPs de datacenters (AWS, GCP, Azure, Docker Cloud) s√£o bloqueados.

### ‚úÖ Testar Localmente (Recomendado)

```bash
# No seu computador local (IP residencial):
git clone <repo>
cd Radar
npm install
cp .env.example .env  # Configurar vari√°veis

# Testar scrapers
node test-stakeholders.js

# Executar scraping completo
npm run scrape
```

### 1. Executar Manualmente

```bash
# Executar todos os scrapers
node src/scrapers/runScraper.js

# Testar apenas stakeholders
node test-stakeholders.js
```

### 2. Via API

```bash
# Executar scraping manual (endpoint a criar)
curl -X POST http://localhost:3000/api/scrape/stakeholders

# Buscar documentos de stakeholders
curl http://localhost:3000/api/stakeholders/documents?categoria=concertacao_social

# Estat√≠sticas
curl http://localhost:3000/api/stakeholders/stats
```

### 3. Filtrar por Categoria/Fonte

```bash
# Documentos da CGTP
curl http://localhost:3000/api/stakeholders/documents?fonte=cgtp

# Documentos de Concerta√ß√£o Social
curl http://localhost:3000/api/stakeholders/documents?categoria=concertacao_social

# Com limite
curl http://localhost:3000/api/stakeholders/documents?categoria=concertacao_social&limit=50
```

## Limita√ß√µes e Desafios

### Prote√ß√£o Anti-Scraping (403 Forbidden)

**Problema Identificado**: Sites portugueses bloqueiam requests de IPs de datacenters/cloud.

Durante testes em ambiente de desenvolvimento (Docker/Cloud):
- ‚ùå Site do Parlamento: Bloqueado (403)
- ‚ùå Sites de Stakeholders: Bloqueados (403)

**Causa Raiz**:
O IP do servidor de desenvolvimento est√° em uma lista negra de datacenters. Sites portugueses implementaram prote√ß√£o forte contra bots:
- Cloudflare ou WAF similar
- Bloqueio de IPs de datacenters AWS/GCP/Azure
- Rate limiting agressivo
- Detec√ß√£o de comportamento n√£o-humano
- Verifica√ß√£o de JavaScript/cookies

**Solu√ß√µes Implementadas** ‚úÖ:
1. M√∫ltiplos User-Agents rotativos
2. Headers HTTP completos
3. Sistema de retry com backoff
4. Suporte a RSS feeds (configurado)

**Solu√ß√µes Recomendadas** üîß:

### ‚úÖ Solu√ß√£o Imediata: Servidor com IP Residencial
```bash
# Executar em servidor local/VPS com IP residencial portugu√™s
# Sites geralmente N√ÉO bloqueiam IPs residenciais
npm run scrape
```

### üîÆ Solu√ß√µes Futuras:

1. **Servidor em Portugal** (Melhor solu√ß√£o)
   - Contratar VPS em Portugal com IP residencial
   - Exemplo: Hetzner Finland, OVH Portugal
   - Custo: ~‚Ç¨5-10/m√™s

2. **Proxy Residencial Rotativo**
   - ScraperAPI: https://www.scraperapi.com/ (~$50/m√™s)
   - BrightData: https://brightdata.com/ (~$100/m√™s)
   - Proxies portugueses espec√≠ficos

3. **Puppeteer/Playwright** (se servidor residencial n√£o funcionar)
   ```bash
   npm install puppeteer
   ```
   Simula navegador real, mas mais lento e pesado

4. **RSS Feeds** (se existirem)
   ```bash
   npm install rss-parser
   ```
   Mais leve, mas nem todos os sites t√™m

5. **APIs Oficiais**
   - Negociar acesso direto com organiza√ß√µes
   - Melhor solu√ß√£o a longo prazo

## Implementa√ß√£o de RSS (Pr√≥ximos Passos)

```javascript
// Adicionar depend√™ncia
npm install rss-parser

// Fun√ß√£o de parsing RSS
async function parseRSS(rssUrl, stakeholderId, config) {
  const Parser = require('rss-parser');
  const parser = new Parser();

  const feed = await parser.parseURL(rssUrl);

  return feed.items.map(item => ({
    tipo_conteudo: config.tipo_conteudo,
    tipo_radar: "stakeholders",
    categoria: config.categoria,
    titulo: item.title,
    data_publicacao: new Date(item.pubDate).toISOString().split('T')[0],
    url: item.link,
    fonte: stakeholderId,
    entidades: config.nome,
    resumo: item.contentSnippet || item.summary,
  }));
}
```

## Estrutura de Dados

### Tabela: `documents`

```sql
CREATE TABLE documents (
  id UUID PRIMARY KEY,
  tipo_conteudo TEXT,           -- "noticia", "comunicado", etc.
  tipo_radar TEXT,              -- "parlamento" | "stakeholders"
  categoria TEXT,               -- "concertacao_social", "laboral", etc.
  titulo TEXT NOT NULL,
  data_publicacao DATE,
  url TEXT UNIQUE NOT NULL,     -- Usado para evitar duplicados
  fonte TEXT,                   -- "cgtp", "ugt", etc.
  entidades TEXT,               -- Nome completo: "CGTP-IN"
  resumo TEXT,
  conteudo TEXT,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- √çndices importantes
CREATE INDEX idx_documents_tipo_radar ON documents(tipo_radar);
CREATE INDEX idx_documents_categoria ON documents(categoria);
CREATE INDEX idx_documents_fonte ON documents(fonte);
CREATE INDEX idx_documents_url ON documents(url);
```

## Monitoriza√ß√£o e Logs

```javascript
// Logs estruturados durante scraping:
üîç Scraping CGTP-IN (cgtp)...
   URL: https://www.cgtp.pt/accao-e-luta
   ‚úì Seletor funcionou: "article h2 a" (15 elementos)
   üìä Encontrados: 15 documentos
   ‚úÖ Novo: Greve dos trabalhadores do Metro de Lisboa marcada para...
   ‚úÖ CGTP-IN: 12 novos, 3 duplicados
```

## Testes

### Script de Teste Completo

```bash
node test-stakeholders.js
```

**Output esperado**:
```
======================================================================
üîç TESTANDO: CGTP-IN (cgtp)
   URL: https://www.cgtp.pt/accao-e-luta
======================================================================
   ‚Üí Fazendo request...
   ‚úì Status: 200
   ‚úì Tamanho da resposta: 245.32 KB

   üîç Testando seletores:
   ‚úÖ "article h2 a": 15 elementos

   üìÑ Primeiros 3 resultados:
      1. Greve dos trabalhadores do Metro...
         URL: /accao-e-luta/2025/10/greve-metro
```

## Troubleshooting

### Erro: "fetch failed" (Supabase)
```bash
# Verificar vari√°veis de ambiente
cat .env | grep SUPABASE

# Testar conex√£o
node -e "import('./src/config/supabase.js').then(m => m.testConnection())"
```

### Erro: "Status 403"
```
Solu√ß√µes:
1. Verificar se o site tem RSS feed
2. Testar com Puppeteer
3. Usar servi√ßo de proxy
4. Contactar administrador do site
```

### Nenhum documento encontrado
```
Poss√≠veis causas:
1. Seletores CSS desatualizados ‚Üí Inspecionar HTML do site
2. Estrutura do site mudou ‚Üí Atualizar configura√ß√£o
3. Site usa JavaScript para carregar conte√∫do ‚Üí Usar Puppeteer
```

## Pr√≥ximos Passos

- [ ] Implementar parser de RSS feeds
- [ ] Adicionar Puppeteer para sites bloqueados
- [ ] Criar endpoint para scraping manual
- [ ] Dashboard de monitoriza√ß√£o
- [ ] Alertas quando scraper falha
- [ ] Backup/restore de configura√ß√µes
- [ ] Testes unit√°rios
- [ ] CI/CD automation

## Contribuir

Para adicionar novo stakeholder:

1. Adicionar configura√ß√£o em `STAKEHOLDERS_CONFIG`
2. Testar seletores com `test-stakeholders.js`
3. Verificar se tem RSS feed
4. Documentar aqui

## Licen√ßa

Propriedade do projeto Radar Legislativo.
